{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952e87eb",
   "metadata": {},
   "source": [
    "# ü§ñ Abschlussprojekt: RAG-System mit AI Index 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461dcb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Ben√∂tigte Bibliotheken\n",
    "!pip install pymupdf langchain tiktoken chromadb sentence-transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10735991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ PDF-Datei hochladen\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c14a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÑ Text aus PDF extrahieren\n",
    "import fitz  # PyMuPDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\".join([page.get_text() for page in doc])\n",
    "pdf_path = 'hai_ai_index_report_2025.pdf'\n",
    "raw_text = extract_text_from_pdf(pdf_path)\n",
    "print(f\"Metin uzunluƒüu: {len(raw_text)} karakter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß© Text in Chunks aufteilen\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(raw_text)\n",
    "print(f\"Toplam {len(chunks)} chunk √ºretildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c70f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè∑Ô∏è Metadaten hinzuf√ºgen\n",
    "from langchain.docstore.document import Document\n",
    "documents = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    metadata = {\"source\": \"AI Index 2025\", \"chunk_id\": i, \"section\": \"Investments\" if i < 50 else \"Other\"}\n",
    "    documents.append(Document(page_content=chunk, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ Indexierung mit ChromaDB\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(documents, embedding=embedding_function, persist_directory=\"rag_index_metadata\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Einfaches Retrieval-Beispiel\n",
    "query = \"What are the main AI investment trends in 2024?\"\n",
    "retrieved_docs = db.similarity_search(query, k=3)\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"--- Chunk {i} ---\\n{doc.page_content[:500]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd305814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Retrieval mit Metadaten-Filterung\n",
    "filtered_docs = db.similarity_search(query, k=3, filter={\"section\": \"Investments\"})\n",
    "for i, doc in enumerate(filtered_docs, 1):\n",
    "    print(f\"--- Filtered Chunk {i} (Section: {doc.metadata['section']}) ---\\n{doc.page_content[:500]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ Mehrfach-Abfrage-Retrieval (Multi-Query Retrieval)\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "multi_retriever = MultiQueryRetriever.from_llm(retriever=db.as_retriever(), llm=llm)\n",
    "docs = multi_retriever.get_relevant_documents(query)\n",
    "for i, doc in enumerate(docs[:3], 1):\n",
    "    print(f\"--- MultiQuery {i} ---\\n{doc.page_content[:500]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e36ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä LangSmith (optionales Tracking und Monitoring)\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"your-langsmith-key\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ Antwortgenerierung mit LLM + RAG\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=db.as_retriever(), chain_type=\"stuff\")\n",
    "response = qa_chain.run(query)\n",
    "print(\"\\nü§ñ Model Cevabƒ±:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Auswertung: Retrieval aktiviert vs. deaktiviert\n",
    "test_questions = [\n",
    "    \"What was the trend in global AI private investment in 2024?\",\n",
    "    \"Which countries led in AI research output in 2024?\",\n",
    "    \"How did AI adoption in education evolve in 2024?\",\n",
    "    \"What ethical concerns about AI are mentioned in the 2025 report?\",\n",
    "    \"Which sectors saw the highest AI implementation growth in 2024?\"\n",
    "]\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n=== Q{i}: {question} ===\")\n",
    "    print(\"\\nüö´ LLM (no retrieval):\")\n",
    "    print(llm.predict(question))\n",
    "    print(\"\\n‚úÖ RAG:\")\n",
    "    print(qa_chain.run(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
